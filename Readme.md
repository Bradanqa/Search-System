# Оглавление

- [1. Класс Spider](#1-класс-spider)
- [2. Класс HttpServer](#2-класс-httpserver)
- [3. Библиотека SrcLib](#3-библиотека-srclib)

## 1. Класс Spider
Реализует веб-краулер, который обходит веб-сайты, начиная с заданного URL, до указанной глубины, загружает HTML-страницы, извлекает из них текст и ссылки, и сохраняет данные в базу данных для последующего поиска.

---
### `Spider(const std::string& start_url, int max_depth, Database& db)`

Конструктор

   - `start_url` — URL, с которого начинается обход.
   - `max_depth` — максимальная глубина рекурсии (1 = только стартовая страница, 2 = стартовая + все ссылки с неё и т.д.).
   - `db` — ссылка на объект базы данных, куда будут сохраняться документы и индекс.

---
### `void Run()`

Запускает процесс краулинга

   - Создаёт таблицы в БД (если их нет).
   - Добавляет стартовый URL в очередь обработки.
   - Запускает пул потоков (Workers), каждый из которых выполняет функцию `Worker()`.
   - Ожидает завершения всех потоков.

---
### `void Worker()`

Рабочая функция потока

   - В бесконечном цикле извлекает URL из очереди `UrlQueue`.
   - Вызывает `ProcessPage(url, depth)` для обработки.
   - Если очередь пуста, поток засыпает на короткое время, чтобы не нагружать CPU.
   - Работает до тех пор, пока не завершится обход (в текущей реализации — пока очередь не опустеет и не будет обработано достаточное число страниц).

---
### `std::string FetchPage(const std::string& url)`

Загружает HTML-страницу по HTTP/HTTPS

   - Возвращает тело ответа (HTML) в виде строки при успехе.
   - Возвращает пустую строку, если:
     - Сервер не отвечает
     - Ошибка соединения
     - Статус ответа не `200 OK`

### `void ProcessPage(const std::string& url, int depth)`

Обрабатывает одну веб-страницу

   - Проверяет, не посещался ли URL ранее (через `Visited`).
   - Загружает HTML через `FetchPage()`.
   - Если HTML получен:
   - Сохраняет URL в таблицу `documents`
   - Парсит HTML: удаляет теги, извлекает слова и ссылки
   - Для каждого слова:
     - Добавляет в таблицу `words` (если новое)
     - Сохраняет частоту в `index_table`
   - Если текущая глубина < `MaxDepth`, извлекает все ссылки и добавляет их в `UrlQueue` с `depth` + 1


## 2. Класс HttpServer

Реализует HTTP-сервер на основе Boost.Beast, который обслуживает веб-интерфейс поисковой системы: отображает форму поиска и обрабатывает поисковые запросы, возвращая результаты из базы данных PostgreSQL.

---
### `HttpServer(int port, Database& db)`

Конструктор
- `port` — номер TCP-порта, на котором сервер будет принимать входящие HTTP-запросы (например, `8080`).
- `db` — ссылка на объект базы данных, используемый для выполнения поисковых запросов.

---
### `void Run()`
Запускает HTTP-сервер

- Создаёт TCP-сокет и привязывается к указанному порту.
- В бесконечном цикле:
  - Принимает входящее соединение
  - Читает HTTP-запрос
  - Передаёт его в `HandleRequest` для обработки
  - Отправляет HTTP-ответ клиенту (браузеру)
- Сервер работает последовательно (один запрос за раз; без поддержки keep-alive или многопоточности для упрощения).

---
### `std::string BuildSearchForm()`
Генерирует HTML-код главной страницы с формой поиска

- Возвращает строку с простым HTML-документом, содержащим:
  - Заголовок
  - Поле ввода (`<input name="q">`)
  - Кнопку «Найти»
- Вызывается при обработке GET-запроса к корню (`/`).

---
### `std::string BuildResultsPage(const std::vector<std::pair<std::string, int>>& results)`
Генерирует HTML-код страницы с результатами поиска

- `results` — вектор пар `(URL, релевантность)`, отсортированный по убыванию релевантности.
- Формирует HTML-страницу, содержащую:
  - Список ссылок на найденные документы
  - Указание релевантности
  - Сообщение «Ничего не найдено», если результатов нет
  - Ссылку «Новый поиск»
- Вызывается после успешного выполнения поиска.

---
### `std::vector<std::string> ParseQuery(const std::string& query_str)`
Анализирует и нормализует поисковый запрос

- Удаляет из строки все символы, кроме букв, цифр и пробелов.
- Приводит текст к нижнему регистру.
- Разбивает на отдельные слова.
- Возвращает вектор нормализованных слов.

---
### `std::vector<std::pair<std::string, int>> PerformSearch(Database& db, const std::vector<std::string>& words)`
Выполняет поиск в базе данных

- Формирует и выполняет SQL-запрос.
- Находит документы, содержащие все слова из запроса.
- Считает суммарную частоту упоминания этих слов в каждом документе.
- Возвращает вектор пар `(URL, суммарная_частота)`.

---
### `void HandleRequest(http::request<htt p::string_body>& req, http::response<http::string_body>& res, Database& db)`
Обрабатывает входящий HTTP-запрос

- Анализирует метод запроса:
  - `GET` → возвращает форму поиска (`BuildSearchForm`)
  - `POST` → извлекает параметр `q`, парсит запрос, выполняет поиск, возвращает результаты (`BuildResultsPage`)
- Устанавливает заголовок `Content-Type: text/html; charset=utf-8`.


## 3. Библиотека SrcLib

Содержит общие функции и классы, используемые в обоих проектах

| Файл                          | Назначение                                                                   |
|-------------------------------|------------------------------------------------------------------------------|
| `Config.h` / `Config.cpp`     | Парсинг и хранение настроек из `config.ini`                                  |
| `Database.h` / `Database.cpp` | Подключение к PostgreSQL и операции с таблицами                              |
| `Utils.h` / `Utils.cpp`       | Вспомогательные функции: очистка HTML, токенизация текста, извлечение ссылок |
